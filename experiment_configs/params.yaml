name: "test"

# --- Misc ---
gpu_id: 0
checkpoints_dir: '/home/awilkins/extrapolation_pix2pix/checkpoints'

# --- Data loading and prep ---
dataroot: "/state/partition1/awilkins/..."
dataroot_shared_disk: "/share/gpu...awilkins/..."
# True: trainA, trainB, validA, validB | False: train, valid
unaligned: True
# If nd data is saved with the sparse library so needs to be read in differently
nd_sparse: True
# Zero padding or cropping to apply to data. Note height is channel and width is tick.
# Unet requires padding to be a multiple of 128 or 256 (for 256: w=56 h=16).
# For resnet, if data was saved with zero padding, can trim it with the crop.
pad_w: 0
pad_h: 0
crop_w: 0
crop_h: 0
# saved (last channel of A contains the mask) | saved_fd (last channel of B contains the mask) |
# auto (make the mask on the fly in the loss function by smearing B) |
# none (no mask stored) | dont_use (mask stored in last channel of A and don't use in loss) |
# none_weighted (no mask stored but use weight non-zero adc in B higher by nonzero_L1weight) |
# saved_1rms (last channel of A contains the mask, only register non-zero loss when difference is
# greater than 1 rms set by rms option)
mask_type: "saved"
# Scale each channel in preprocessing. See scalefactors.yaml for list of scalefactors for datasets.
A_ch_scalefactors:
  - 0.00078125
  - 0.14085904245475275
  - 0.05645979274839422
  - 0.020833333333333332
  - 0.03225806451612903
  - 4.175365344467641
  - 0.02063983488132095
B_ch_scalefactors:
  - 0.00031298904538341156
input_nc: 7
output_nc: 1
direction: 'AtoB'
# If any of the image is zeros we can set channel_offset and tick_offset to ignore the zeros in
#the loss and the discriminator
channel_offset: 0
tick_offset: 0
# Add a channel to A of Gaussian noise each time it is loaded
noise_layer: False
# -1 (pass the whole image) |
# >= 0 (split image into random tick ranges 512 long, current implementation is broken)
samples: -1

# --- Model and training ---
# Number of filters at bottlenecks (where there are the most)
ngf: 64
ndf: 64
# n_layers | basic | pixel
netD: 'n_layers'
# Remove the adversarial component entirely
no_D_test: False
# resnet_9blocks | resnet_6blocks | resnet_9blocks_downres(4,10)_1 |
# resnet_9blocks_downres(4,10)_2 | resnet_9blocks_downres(8,8)_1 | resnet_9blocks_downres(8,8)_2 |
# resnet_9blocks_downres(8,8)_3 | unet_128 | unet_256 | unet_256_k3 | unet_256_k3-5 |
# unet_256_k3-5_strides1 | unet_256_k3-5_strides2 | unet_256_strides1
# downres modes produce an output smaller than input
# (for experimenting with high resolution wire projections)
netG: "unet_256"
# default was 5
n_layers_D: 4
# batch | instance | none
norm: 'batch'
# normal | xavier | kaiming | orthogonal
# Most success with xavier and orthogonal
init_type: 'xavier'
init_gain: 0.02
no_dropout: False
n_epochs: 12
n_epochs_decay: 5
beta1: 0.5
# default was 0
adam_weight_decay: 0.0001
# Typically [0.00001, 0.0002]
lr: 0.0001
# vanilla | lsgan | wgangp
gan_mode: 'vanilla'
# linear | step | plateau | cosine
lr_policy : 'linear'
lr_decay_iters : 50
isTrain: True
lambda_pix: 1000
# See mask_type=none_weighted
nonzero_L1weight: 10
lambda_channel: 20
# identity | tanh | linear | relu | tanh+clampcollection | tanh+clampinduction
# The clamp output layers are scaled for induction and collection assuming normalisation to [-1, 1]
# that retains the positions of zero ie. divided by max(abs(min(adcs)), abs(max(adcs)))
G_output_layer: 'tanh+clampcollection'
# D takes the output image without the input concatenated (useful for interacting with CycleGAN)
unconditional_D: False
# reflect | zeros
padding_type: 'reflect'
# Only for mask_type=saved_1rms
rms : 3.610753167639414

# --- Training misc ---
serial_batches: False
num_threads: 4
batch_size : 1
max_dataset_size: 18000

# --- Logging ---
display_freq : 2000
print_freq: 100
# "epoch" for at the end of each epoch
valid_freq: 9000
num_valid: 1000
save_latest_freq: 10000
save_epoch_freq: 4

